library(ISLR)
install.packages("ISLR")
library(ISLR)
attach(Wage)
library(ISLR)
attach(Wage)
train=sample(1:nrow(age),nrow/2)
train.Wage=Wage[train]
train=sample(1:nrow(age),nrow(age)/2)
train.Wage=Wage[train]
nrow(age)
age
nrow(Wage)
nrow(Wage$age)
nrow(age$Wage)
train=sample(1:nrow(Wage),nrow(Wage)/2)
train.Wage=Wage[train]
train.Wage=Wage[train,]
nrow(train.Wage=Wage[train,])
nrow(train.Wage)
source('~/unit6.R')
train_pl_1=lm(wage~poly{age,1),data=train.Wage)
train_pl_1=lm(wage~poly(age,1),data=train.Wage)
train_pl_1=lm(wage~poly(age,1),data=train.Wage)
train_pl_1=lm(wage~poly(age,1),data=train.Wage)
train_pl_2=lm(wage~poly(age,2),data=train.Wage)
train_pl_3=lm(wage~poly(age,3),data=train.Wage)
train_pl_4=lm(wage~poly(age,4),data=train.Wage)
train_pl_5=lm(wage~poly(age,5),data=train.Wage)
train_pl_6=lm(wage~poly(age,6),data=train.Wage)
train_pl_7=lm(wage~poly(age,7),data=train.Wage)
anova(train_pl_1,train_pl_2,train_pl_3,train_pl_4,train_pl_5,train_pl_6,train_pl_7)
source('~/unit6.R')
summary(train_pl_7)
source('~/unit6.R')
DATA_FOLDER = "D:\\Successful_Campaign\\Dane_20_04_2017"
succ_datt = read.table(file=paste(DATA_FOLDER,"succ_datt.txt",sep = "\\"),sep=" ", header=TRUE)
summary(succ_datt)
succ_datt$Investment=succ_datt$Investment/10^4  # transform Investment dividing by    10 000 zł
succ_datt$GRP_abs. = succ_datt$GRP_abs./10^6    # transform GRP_abs.   dividing by 1 000 000
succ_datt$ReachAbs = succ_datt$ReachAbs/10^5    # transform ReachAbs   dividing by   100 000
succ_numvar = succ_datt[,-c(1,2,25)]
names(succ_numvar)
library(caret)
nearZeroVar(succ_datt)
install.packages("caret")
plot(cars)
plot(cars)
#' na ktĂłre mieszkania staÄ‡ WrocĹ‚awian?
#'
#' WedĹ‚ug GUS (http://wroclaw.stat.gov.pl/) przeciÄ™tne (Ĺ›rednie)
#' wyngrodzenie we WrocĹ‚awiu wyniosĹ‚o 4532,14 zĹ‚ brutto.
#' To jest 3 223,81 zĹ‚ netto
pensja <- 3223.81
#odjmiemy 1500 zĹ‚otych na ĹĽycie (jedzenie, ubrania, rozrywkÄ™)
max_rata <- pensja - 1500
#zalozmy kredyt na 5% rocznie
# rata = kwota kredytu * (1 + procent/12)^ liczba_rat * ((1 + procent/12)-1)/((1 + procent/12)^liczba_rat-1)
liczba_rat <- 25*12
r <- 0.05
max_rata/(1 + r/12)^liczba_rat/((1 + r/12)-1)*((1 + r/12)^liczba_rat-1)
#wychodzi 300K kredytu
library(dplyr)
library(mlr)
mieszkania <- na.omit(read.csv(file = "./data/mieszkania_dane.csv", encoding = "UTF-8"))
mieszkania <- mieszkania %>%
mutate(cena = metraz*cena_m2) %>%
mutate(tanie = cena < 300000) %>%
select(-cena)
#' Pytanie: Jaki procent mieszkaĹ„ ma cenÄ™ poniĹĽej 300K zĹ‚otych?
predict_affordable <- makeClassifTask(id = "affordableApartments",
data = mieszkania, target = "tanie")
all_learners <- listLearners()
filter(all_learners, type == "classif")[["class"]]
learnerRF <- makeLearner("classif.randomForest")
learnerNN <- makeLearner("classif.nnet")
learnerGLM <- makeLearner("classif.glmnet")
bench_regr <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable))
#jak policzyÄ‡ AUC?
#potrzebujemy p-stw, a nie tylko etykietek, zmieniamy opcjÄ™ predict.type
learnerGLM <- makeLearner("classif.glmnet", predict.type = "prob")
# zamiast crossval moĹĽemy uĹĽyÄ‡ innych sposobĂłw weryfikacji dobroci modeli,
# np. holdout czy repcv (wiÄ™cej info w dokumentacji)
GLM_probs = crossval(learnerGLM, predict_affordable)
performance(GLM_probs$pred, measures = list(auc))
listMeasures(predict_affordable)
#' Pytanie: porĂłwnaj modele oparte o lasy losowe i sieci neuronowe
#' pod wzgledem auc i false positives (fp), czyli mieszkaĹ„, ktĂłre
#' przewidujemy jako tansze, ale w istocie takie nie sa
#### KtĂłre zmienne sÄ… istotne i jaki majÄ… wpĹ‚yw na koszt mieszkania?
#uczymy uogĂłlniony model liniowy z lasso z konkretnÄ… wartoĹ›ciÄ… lambda
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.00001)
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable)
#parametry dopasowanego modelu
getLearnerModel(learnerGLM_one_lambda)$beta
#jak poprawiÄ‡ model? DodaÄ‡ nowe waĹĽne zmienne
mieszkanie_new_features <- mieszkania %>%
mutate(pietro = ifelse(pietro == 0, "parter",
ifelse(pietro == pietro_maks, "ostatnie_pietro",
ifelse(pietro > 15, "wysoko",
ifelse(pietro_maks < 3, "niska_zabudowa", "inne")))),
pietro = factor(pietro),
rok = ifelse(rok < 1945, "przedwojenne",
ifelse(rok < 1970, "powojenne",
ifelse(rok < 1989, "wielka_plyta", "po_1989"))),
rok = factor(rok))
predict_affordable_new_features <-
makeClassifTask(id = "affordableApartments", data = mieszkanie_new_features,
target = "tanie")
# Pytanie: czy mamy lepszÄ… predykcjÄ™ dla modelu learnerGLM dla nowych danych?
#### IstotnoĹ›Ä‡ wspĂłĹ‚czynnikĂłw i interpretacja
#uczymy uogĂłlniony model liniowy z lasso z konkretnÄ… wartoĹ›ciÄ… lambda
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.0001)
#lambde da sie wybrac w systematyczny sposob za pomoca mlr
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable_new_features)
#parametry dopasowanego modelu
knitr::kable(as.matrix(getLearnerModel(learnerGLM_one_lambda)$beta))
# Pytanie: jak naleĹĽy interpretowaÄ‡ te wspĂłĹ‚czynniki?
# Podobnie moĹĽemy sprawdziÄ‡, ktĂłre zmienne sÄ… istotne w modelu lasu losowego?
learnerRF_imp_trained <- train(learnerRF, predict_affordable_new_features)
getFeatureImportance(learnerRF_imp_trained)
pensja <- 3223.81
#odjmiemy 1500 zĹ‚otych na ĹĽycie (jedzenie, ubrania, rozrywkÄ™)
max_rata <- pensja - 1500
#zalozmy kredyt na 5% rocznie
# rata = kwota kredytu * (1 + procent/12)^ liczba_rat * ((1 + procent/12)-1)/((1 + procent/12)^liczba_rat-1)
liczba_rat <- 25*12
r <- 0.05
max_rata/(1 + r/12)^liczba_rat/((1 + r/12)-1)*((1 + r/12)^liczba_rat-1)
#wychodzi 300K kredytu
library(dplyr)
library(mlr)
install.packages("mlr")
install.packages("dplyr")
pensja <- 3223.81
#odjmiemy 1500 zĹ‚otych na ĹĽycie (jedzenie, ubrania, rozrywkÄ™)
max_rata <- pensja - 1500
#zalozmy kredyt na 5% rocznie
# rata = kwota kredytu * (1 + procent/12)^ liczba_rat * ((1 + procent/12)-1)/((1 + procent/12)^liczba_rat-1)
liczba_rat <- 25*12
r <- 0.05
max_rata/(1 + r/12)^liczba_rat/((1 + r/12)-1)*((1 + r/12)^liczba_rat-1)
#wychodzi 300K kredytu
library(dplyr)
library(mlr)
mieszkania <- na.omit(read.csv(file = "./data/mieszkania_dane.csv", encoding = "UTF-8"))
mieszkania <- mieszkania %>%
mutate(cena = metraz*cena_m2) %>%
mutate(tanie = cena < 300000) %>%
select(-cena)
#' Pytanie: Jaki procent mieszkaĹ„ ma cenÄ™ poniĹĽej 300K zĹ‚otych?
predict_affordable <- makeClassifTask(id = "affordableApartments",
data = mieszkania, target = "tanie")
all_learners <- listLearners()
filter(all_learners, type == "classif")[["class"]]
learnerRF <- makeLearner("classif.randomForest")
learnerNN <- makeLearner("classif.nnet")
learnerGLM <- makeLearner("classif.glmnet")
bench_regr <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable))
#jak policzyÄ‡ AUC?
#potrzebujemy p-stw, a nie tylko etykietek, zmieniamy opcjÄ™ predict.type
learnerGLM <- makeLearner("classif.glmnet", predict.type = "prob")
# zamiast crossval moĹĽemy uĹĽyÄ‡ innych sposobĂłw weryfikacji dobroci modeli,
# np. holdout czy repcv (wiÄ™cej info w dokumentacji)
GLM_probs = crossval(learnerGLM, predict_affordable)
performance(GLM_probs$pred, measures = list(auc))
listMeasures(predict_affordable)
#' Pytanie: porĂłwnaj modele oparte o lasy losowe i sieci neuronowe
#' pod wzgledem auc i false positives (fp), czyli mieszkaĹ„, ktĂłre
#' przewidujemy jako tansze, ale w istocie takie nie sa
#### KtĂłre zmienne sÄ… istotne i jaki majÄ… wpĹ‚yw na koszt mieszkania?
#uczymy uogĂłlniony model liniowy z lasso z konkretnÄ… wartoĹ›ciÄ… lambda
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.00001)
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable)
#parametry dopasowanego modelu
getLearnerModel(learnerGLM_one_lambda)$beta
#jak poprawiÄ‡ model? DodaÄ‡ nowe waĹĽne zmienne
mieszkanie_new_features <- mieszkania %>%
mutate(pietro = ifelse(pietro == 0, "parter",
ifelse(pietro == pietro_maks, "ostatnie_pietro",
ifelse(pietro > 15, "wysoko",
ifelse(pietro_maks < 3, "niska_zabudowa", "inne")))),
pietro = factor(pietro),
rok = ifelse(rok < 1945, "przedwojenne",
ifelse(rok < 1970, "powojenne",
ifelse(rok < 1989, "wielka_plyta", "po_1989"))),
rok = factor(rok))
predict_affordable_new_features <-
makeClassifTask(id = "affordableApartments", data = mieszkanie_new_features,
target = "tanie")
# Pytanie: czy mamy lepszÄ… predykcjÄ™ dla modelu learnerGLM dla nowych danych?
#### IstotnoĹ›Ä‡ wspĂłĹ‚czynnikĂłw i interpretacja
#uczymy uogĂłlniony model liniowy z lasso z konkretnÄ… wartoĹ›ciÄ… lambda
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.0001)
#lambde da sie wybrac w systematyczny sposob za pomoca mlr
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable_new_features)
#parametry dopasowanego modelu
knitr::kable(as.matrix(getLearnerModel(learnerGLM_one_lambda)$beta))
# Pytanie: jak naleĹĽy interpretowaÄ‡ te wspĂłĹ‚czynniki?
# Podobnie moĹĽemy sprawdziÄ‡, ktĂłre zmienne sÄ… istotne w modelu lasu losowego?
learnerRF_imp_trained <- train(learnerRF, predict_affordable_new_features)
getFeatureImportance(learnerRF_imp_trained)
listMeasures(predict_affordable)
install.packages(c("mlr", "dplyr", "randomForest", "nnet", "glmnet", "kernlab"))
install.packages(c("mlr", "dplyr", "randomForest", "nnet", "glmnet", "kernlab"))
pensja <- 3223.81
#odjmiemy 1500 zĹ‚otych na ĹĽycie (jedzenie, ubrania, rozrywkÄ™)
max_rata <- pensja - 1500
#zalozmy kredyt na 5% rocznie
# rata = kwota kredytu * (1 + procent/12)^ liczba_rat * ((1 + procent/12)-1)/((1 + procent/12)^liczba_rat-1)
liczba_rat <- 25*12
r <- 0.05
max_rata/(1 + r/12)^liczba_rat/((1 + r/12)-1)*((1 + r/12)^liczba_rat-1)
library(dplyr)
library(mlr)
mieszkania <- na.omit(read.csv(file = "./data/mieszkania_dane.csv", encoding = "UTF-8"))
mieszkania <- mieszkania %>%
mutate(cena = metraz*cena_m2) %>%
mutate(tanie = cena < 300000) %>%
select(-cena)
mieszkania <- na.omit(read.csv(file = "./data/mieszkania_dane.csv", encoding = "UTF-8"))
library(dplyr)
library(mlr)
mieszkania <- na.omit(read.csv(file = "./data/mieszkania_dane.csv", encoding = "UTF-8"))
setwd("C:\\Users\\Mediapol\\Documents\\GitHub\\STWUR-2017-06-07")
mieszkania <- na.omit(read.csv(file = "./data/mieszkania_dane.csv", encoding = "UTF-8"))
mieszkania <- mieszkania %>%
mutate(cena = metraz*cena_m2) %>%
mutate(tanie = cena < 300000) %>%
select(-cena)
predict_affordable <- makeClassifTask(id = "affordableApartments",
data = mieszkania, target = "tanie")
all_learners <- listLearners()
filter(all_learners, type == "classif")[["class"]]
learnerRF <- makeLearner("classif.randomForest")
learnerNN <- makeLearner("classif.nnet")
learnerGLM <- makeLearner("classif.glmnet")
bench_regr <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable))
learnerGLM <- makeLearner("classif.glmnet", predict.type = "prob")
GLM_probs = crossval(learnerGLM, predict_affordable)
performance(GLM_probs$pred, measures = list(auc))
bench_regr <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable))
learnerNN<-makeLearner("classif.nnet", predict.type = "prob")
learnerNN<-makeLearner("classif.randomForest", predict.type = "prob")
learnerNN<-makeLearner("classif.nnet", predict.type = "prob")
learnerRF<-makeLearner("classif.randomForest", predict.type = "prob")
bench_class <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable))
getBMRAggrPerformances(bench_class)
learnerNN<-makeLearner("classif.nnet", predict.type = "prob")
NN_probs = crossval(learnerNN, predict_affordable)
performance(NN_probs$pred, measures = list(auc))
learnerRF<-makeLearner("classif.randomForest", predict.type = "prob")
RF_probs = crossval(learnerRF, predict_affordable)
performance(RF_probs$pred, measures = list(auc))
learnerGLM <- makeLearner("classif.glmnet", predict.type = "prob")
GLM_probs = crossval(learnerGLM, predict_affordable)
performance(GLM_probs$pred, measures = list(auc))
getBMRAggrPerformances(bench_class)
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.00001)
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable)
getLearnerModel(learnerGLM_one_lambda)$beta
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable)
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable)
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.00001)
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable)
getLearnerModel(learnerGLM_one_lambda)$beta
mieszkanie_new_features <- mieszkania %>%
mutate(pietro = ifelse(pietro == 0, "parter",
ifelse(pietro == pietro_maks, "ostatnie_pietro",
ifelse(pietro > 15, "wysoko",
ifelse(pietro_maks < 3, "niska_zabudowa", "inne")))),
pietro = factor(pietro),
rok = ifelse(rok < 1945, "przedwojenne",
ifelse(rok < 1970, "powojenne",
ifelse(rok < 1989, "wielka_plyta", "po_1989"))),
rok = factor(rok))
predict_affordable_new_features <-
makeClassifTask(id = "affordableApartments", data = mieszkanie_new_features,
target = "tanie")
predict_affordable_new_features <-
makeClassifTask(id = "affordableApartments", data = mieszkanie_new_features,
target = "tanie")
bench_regr <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable_new_features))
bench_class2 <- benchmark(learners = list(learnerRF,
learnerNN,
learnerGLM),
tasks = list(predict_affordable_new_features))
getBMRAggrPerformances(bench_class2)
learnerGLM_one_lambda <- makeLearner("classif.glmnet", lambda = 0.0001)
learnerGLM_one_lambda <- train(learnerGLM_one_lambda, predict_affordable_new_features)
knitr::kable(as.matrix(getLearnerModel(learnerGLM_one_lambda)$beta))
learnerRF_imp_trained <- train(learnerRF, predict_affordable_new_features)
getFeatureImportance(learnerRF_imp_trained)
